# -*- coding: utf-8 -*-
"""first_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vOuG6oHyQd4x8Bolj6YiNSp1zWkJK5G9
"""

import numpy
from tensorflow.keras.constraints import  max_norm
from tensorflow.keras.utils import to_categorical  # تغییر این خط
from tensorflow.keras.datasets import cifar10
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.models import Sequential,load_model
import seaborn as sns

from keras.layers import BatchNormalization, Conv2D, MaxPool2D, Dense, Dropout,Flatten
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

(X_train,y_train),(X_test,y_test) = cifar10.load_data()


print("X_train:", X_train.shape)
print("y_train:", y_train.shape)
print("X_test:", X_test.shape)
print("y_test:", y_test.shape)



x_train =X_train.astype('float32')
X_test =X_test.astype('float32')
X_train =X_train /255.0
X_test =X_test / 255.0



y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
y_test.shape



num_class=10
model=Sequential()

model.add(Conv2D(32,(3,3),padding='same',input_shape=X_train.shape[1:],activation='relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Conv2D(64,(3,3),padding='same',activation='relu'))
model.add(MaxPool2D())
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Conv2D(64,(3,3),padding='same',activation='relu'))
model.add(MaxPool2D())

model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Conv2D(128,(3,3),padding='same',activation='relu'))
model.add(MaxPool2D())
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Flatten())
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Dense(32,activation='relu'))
model.add(Dense(num_class,activation='softmax'))
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

history= model.fit(X_train,y_train, validation_data=(X_test,y_test),epochs=30,batch_size =64)





"""# New Section"""

for key,val in history.history.items():
  print(key)

import pandas as pd
  pd.DataFrame(history.history).plot()

plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.show()

model.save('cvv.h5')

model2=load_model('cvv.h5')
model2.predict(X_test[0:10])[0]



import seaborn as sns  # فراموش نکن seaborn هم باید import بشه
import numpy as np

prediction=model.predict(X_test)



prediction_labels = np.argmax(prediction, axis=1)


y_test_labels = np.argmax(y_test, axis=1)
print(y_test_labels)

# cm = confusion_matrix(y_test_labels, prediction_labels)


# # لیبل‌های کلاس‌ها (CIFAR-10)
# labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',
#           'dog', 'frog', 'horse', 'ship', 'truck']

# sns.heatmap(cm,cbar=False,xticklabels=labels,yticklabels=labels,
#             fmt='d', annot=True,cmap=plt.cm.Blues)
# plt.xlabel('pre')
# plt.ylabel('ac')
# plt.show()

